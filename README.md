# Jenseira - AI-Powered Talking Avatar

> âœ… **Clean & Production Ready**

![Jenseira Avatar](./assets/jenseira-screenshot.png)

An interactive 3D avatar with AI-powered conversations, text-to-speech, and accurate lip-sync animation.

## âœ¨ Features

- ğŸ¤– **AI Conversations** - Powered by LM Studio (Qwen3-VL-4B) with Tavily Search
- ğŸ¤ **Text-to-Speech** - High-quality voice synthesis with Supertonic
- ğŸ‘„ **Lip Sync** - Accurate phoneme-based animation
- ğŸ­ **3D Avatar** - Interactive Ready Player Me avatars
- âš¡ **Real-time** - Fast response and smooth animations
- ğŸ” **Web Search** - Real-time information via Tavily API

## ğŸ¯ Tech Stack

**Frontend:**
- Next.js 15 + TypeScript
- React 19
- Tailwind CSS v4
- Three.js + TalkingHead Library

**Backend:**
- Express.js + Node.js
- LM Studio (Qwen3-VL-4B) via OpenAI API
- LangChain Agent with Tavily Search
- Supertonic TTS (HuggingFace)
- CMU Pronunciation Dictionary

## ğŸš€ Quick Start

**Prerequisites:**
- Install and run [LM Studio](https://lmstudio.ai/) with `qwen/qwen3-vl-4b` model
- Start LM Studio server on `http://localhost:1234`

**1. Setup Environment**
```bash
# Create .env file in root directory
PORT=3001
TAVILY_API_KEY=your_tavily_api_key_here
OPENAI_API_KEY=lm-studio
OPENAI_API_BASE=http://localhost:1234/v1
```

**2. Start Backend**
```bash
cd backend
npm install
npm start
```
Backend runs at `http://localhost:3001`

**3. Start Frontend (Next.js)**
```bash
cd frontend
npm install
npm run dev
```
Frontend runs at `http://localhost:3000`

**4. Open Browser**
Navigate to `http://localhost:3000` and start chatting with Jenseira!

## ğŸ® Usage

1. Type your message in the input box
2. Press Enter or click Send
3. Jenseira responds with AI-generated speech and lip-sync

Features:
- AI-powered conversations using LM Studio (local LLM)
- Real-time web search via Tavily API
- Real-time text-to-speech with accurate lip-sync
- Interactive animations and gestures
- Dark/Light theme toggle
- Mute/Unmute audio controls

## ğŸ”Œ API Endpoints

### POST /tts
Generate AI response with speech and lip-sync data

```bash
curl -X POST http://localhost:3001/tts \
  -H "Content-Type: application/json" \
  -d '{"text": "Hello!"}'
```

Response includes:
- AI-generated text response
- Audio data (Float32Array)
- Phonemes for lip-sync
- Duration timings

### GET /animation/stream
Server-Sent Events stream for real-time avatar animations

### GET /health
Health check

```bash
curl http://localhost:3001/health
```

## ğŸ“ Project Structure

```
jenseira-live-chat/
â”œâ”€â”€ backend/                    # Express.js API
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ cmudict.json       # Pronunciation dictionary
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ animation-stream.js # SSE for animations
â”‚   â”‚   â”œâ”€â”€ avatar.js          # Avatar commands
â”‚   â”‚   â”œâ”€â”€ llm.js             # LLM endpoint
â”‚   â”‚   â””â”€â”€ tts.js             # TTS endpoint
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ avatar.js          # Avatar service
â”‚   â”‚   â”œâ”€â”€ gemini.js          # Gemini AI
â”‚   â”‚   â”œâ”€â”€ tts.js             # TTS generation
â”‚   â”‚   â””â”€â”€ phoneme.js         # Phoneme processing
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ fastPhonemeDurations.js  # Duration estimation
â”‚   â”œâ”€â”€ voices/                # Voice embeddings (F1, F2, M1, M2)
â”‚   â”œâ”€â”€ server.js              # Express server
â”‚   â”œâ”€â”€ .env                   # Environment variables
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ frontend/                   # Next.js 15 Frontend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ page.tsx           # Main page
â”‚   â”‚   â”œâ”€â”€ layout.tsx         # Root layout
â”‚   â”‚   â””â”€â”€ globals.css        # Global styles
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â””â”€â”€ AvatarChat.tsx     # Main chat component
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”œâ”€â”€ useAvatar.ts       # Avatar hook
â”‚   â”‚   â””â”€â”€ useChat.ts         # Chat hook
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ constants/
â”‚   â”‚   â”‚   â”œâ”€â”€ config.ts      # Avatar config
â”‚   â”‚   â”‚   â””â”€â”€ visemes.ts     # Phoneme mapping
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ api.ts         # API client
â”‚   â”‚   â”‚   â”œâ”€â”€ avatar.ts      # Avatar loader
â”‚   â”‚   â”‚   â”œâ”€â”€ avatar-controller.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ speech.ts      # Speech service
â”‚   â”‚   â”‚   â””â”€â”€ talkinghead-loader.ts
â”‚   â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â”‚   â””â”€â”€ index.ts       # TypeScript types
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ audio.ts       # Audio utilities
â”‚   â”‚       â”œâ”€â”€ viseme-converter.ts
â”‚   â”‚       â””â”€â”€ word-timing.ts
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â””â”€â”€ avatars/
â”‚   â”‚       â””â”€â”€ jenseira.glb   # 3D avatar model
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ assets/                     # Screenshots and media
â”œâ”€â”€ docker-compose.yml          # Docker setup
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ğŸ”„ Architecture

**Clean Separated Architecture:**
- âœ… Backend: Express.js REST API (Port 3001)
- âœ… Frontend: Static files (Port 3000)
- âœ… CORS enabled
- âœ… Modular structure
- âœ… Production ready

## ğŸ› ï¸ Development

**Backend:**
```bash
cd backend
npm run dev
# Server auto-restarts with nodemon
```

**Frontend:**
```bash
cd frontend
npm run dev
# Next.js hot reload enabled
```

**Docker (Optional):**
```bash
docker-compose up
# Runs both frontend and backend
```

## âš™ï¸ Customization

### Change Voice
Edit `backend/services/tts.js`:
```javascript
const voiceBuffer = await fs.readFile("../voices/F1.bin"); // F1, F2, M1, or M2
```

### Change Avatar
Edit `frontend/lib/constants/config.ts`:
```typescript
export const AVATAR_CONFIG = {
  DEFAULT_AVATAR: '/avatars/jenseira.glb',
  BODY_TYPE: 'F',
  MOOD: 'neutral',
}
```

### Change AI Model
Edit `backend/services/gemini.js`:
```javascript
const model = new ChatOpenAI({
  model: "qwen/qwen3-vl-4b",  // Change to any LM Studio model
  temperature: 0.7,
  configuration: {
    baseURL: LM_STUDIO_BASE_URL,
  },
});
```

### Customize System Prompt
Edit `backend/services/gemini.js`:
```javascript
systemPrompt: "You are a helpful assistant. Your name is Jenseira..."
```

### Switch to Cloud AI (Optional)
To use OpenAI/Gemini instead of LM Studio:
1. Update `.env` with your API key
2. Modify `backend/services/gemini.js` to use the appropriate SDK

## ğŸ“Š Performance

- **First load**: ~2s (avatar loading)
- **TTS generation**: ~2-3s
- **Lip sync**: Real-time, 60fps
- **Memory**: ~500MB (backend), ~200MB (frontend)

## ğŸš¢ Deployment

**Using Docker:**
```bash
docker-compose up -d
```

**Manual Deployment:**

Backend:
```bash
cd backend
npm install --production
npm start
```

Frontend:
```bash
cd frontend
npm install
npm run build
npm start
```

Deploy frontend build to Vercel, Netlify, or any Node.js hosting platform.

## ğŸ¤ Contributing

This is a clean, modular codebase. Feel free to:
- Add new voices
- Add new avatars
- Improve lip-sync accuracy
- Add new features

## ğŸ“„ License

ISC

## ğŸ‘¤ Author

aakashjammula
